---
title: "Tutorial: Observability"
description: "In just a few lines of code, monitor your AI operations seamlessly."
---

<Tip>
This tutorial is for users who want to use Pezzo for observability and monitoring only.

If you also want to use Pezzo to manage your prompts, version control and prompt deployment, check out the [Prompt Management tutorial](/introduction/tutorial-prompt-management/overview).
</Tip>

**Prefer a video tutorial?** We've prepared a 5-minute video for you! If you want to see the code example, [it's available on Codesandbox](https://codesandbox.io/p/sandbox/pezzo-example-observability-6d2qp6?file=%2Fsrc%2Fapp.ts%3A1%2C1).


<div style={{
  position: "relative",
  paddingBottom: "62.5%",
  height: 0
}}>
  <iframe
    src="https://www.loom.com/embed/dd2276e912834b6c8d67f1355e449cae?sid=d6cea226-90bc-4586-ab6c-7150369b06c9"
    frameborder="0"
    webkitallowfullscreen
    mozallowfullscreen
    allowfullscreen
    style={{ position: "absolute", top: 0, left: 0, width: "100%", height: "100%" }}
  ></iframe>
</div>

## What you'll learn

You're going to learn how to easily use Pezzo to supercharge your AI operations with monitoring and observability. It takes just a few lines of code!

<Note>
  This tutorial assumes you already signed up to Pezzo Cloud and created a new
  project. If you haven't done so, please [sign up to Pezzo
  Cloud](https://app.pezzo.ai).
</Note>

## Install depdendencies

Install the Pezzo Client and the OpenAI SDK:

```bash
npm i @pezzo/client openai
```

## Making calls to OpenAI

Here is a code example:

```ts app.ts
import { Pezzo, PezzoOpenAI } from "@pezzo/client";

// Initialize the Pezzo client
const pezzo = new Pezzo({
  apiKey: "<Your Pezzo API key>",
  projectId: "<Your Pezzo project ID>",
  environment: "Production",
});

// Initialize the OpenAI client
const openai = new PezzoOpenAI(pezzo);

async function main() {
  // Make calls to the OpenAI API as you normally would!
  const completion = await openai.chat.completions.create(
    {
      model: "gpt-3.5-turbo",
      temperature: 0,
      messages: [
        {
          role: "user",
          content: "Tell me {numFacts} fun facts about {topic}",
        },
      ],
    },
    {
      variables: {
        // You can define variables that will be interpolated during execution.
        numFacts: 3,
        topic: "Artificial Intelligence",
      },
      properties: {
        // You can optionally specify custom properties that will be associated with the request.
        someProperty: "someValue",
      },
    }
  );
}

main();

```

[Click here to run this example on CodeSandbox](https://codesandbox.io/p/sandbox/pezzo-example-observability-6d2qp6?file=%2Fsrc%2Fapp.ts%3A1%2C1)

**Let's explain what's going on here:**

- First, we initialize the Pezzo client and the OpenAI client. We pass the Pezzo client to the OpenAI client so it can use it to fetch the prompt.
- Then, we make a call to the OpenAI API as we normally would.
- (Optional) We specify additional parameters in the second argument, these are `variables` and `properties`.

The result will go directly to OpenAI and the response will be reported to Pezzo.

## Monitoring Requests

After integrating with Pezzo and making some requests to OpenAI, you should see all historical requests in the **Requests** view in Pezzo.

If you want to learn more about Pezzo's observability feature, check out the [Observability section in the docs](/platform/observability/overview).

<Frame caption="Pezzo Project Requests View">
  <img src="/platform/observability/requests-view.png" />
</Frame>
