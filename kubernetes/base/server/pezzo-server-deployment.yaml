apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f ./docker-compose.yaml
    kompose.version: 1.32.0 (HEAD)
  labels:
    io.kompose.service: llm-ops-server
  name: llm-ops-server
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: llm-ops-server
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f ./docker-compose.yaml
        kompose.version: 1.32.0 (HEAD)
      labels:
        io.kompose.network/dp-llm-ops-default: "true"
        io.kompose.service: llm-ops-server
    spec:
      containers:
        - env:
            - name: CONSOLE_HOST
              valueFrom:
                configMapKeyRef:
                  key: CONSOLE_HOST
                  name: llm-ops-server-env
            - name: DATABASE_URL
              valueFrom:
                configMapKeyRef:
                  key: DATABASE_URL
                  name: llm-ops-server-env
#            - name: KAFKA_BROKERS
#              valueFrom:
#                configMapKeyRef:
#                  key: KAFKA_BROKERS
#                  name: llm-ops-server-env
            - name: KMS_LOCAL_ENDPOINT
              value: http://llm-ops-local-kms:9981
#            - name: OPENSEARCH_URL
#              valueFrom:
#                configMapKeyRef:
#                  key: OPENSEARCH_URL
#                  name: llm-ops-server-env
            - name: PINO_PRETTIFY
              valueFrom:
                configMapKeyRef:
                  key: PINO_PRETTIFY
                  name: llm-ops-server-env
            - name: SUPERTOKENS_CONNECTION_URI
              valueFrom:
                configMapKeyRef:
                  key: SUPERTOKENS_CONNECTION_URI
                  name: llm-ops-server-env
          image: llm-ops-server:latest
          livenessProbe:
            exec:
              command:
                - curl 'http://llm-ops-server:3000/api/healthz'
            failureThreshold: 5
            periodSeconds: 10
            timeoutSeconds: 5
          name: llm-ops-server
          ports:
            - containerPort: 3000
              hostPort: 3000
              protocol: TCP
      restartPolicy: Always
